<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
  
    
  
    <link rel="alternate" type="application/rss+xml" href="/rss.xml" />
    
    <link rel="shortcut icon" type="image/ico" href="https://a0.awsstatic.com/libra-css/images/site/fav/favicon.ico"/>
    <link rel="apple-touch-icon" sizes="57x57" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-iphone-114-smile.png"/>
    <link rel="apple-touch-icon" sizes="72x72" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-ipad-144-smile.png"/>
    <link rel="apple-touch-icon" sizes="114x114" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-iphone-114-smile.png"/>
    <link rel="apple-touch-icon" sizes="144x144" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-ipad-144-smile.png"/>  
  
    <title>Registry of Open Data on AWS</title>
  
    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://assets.opendata.aws/css/bootstrap/3.4.1/bootstrap.min.css">
  
    <!-- Our local CSS -->
    <link rel="stylesheet" href="/css/main.css">
  
  
  </head>
  <body>
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://assets.opendata.aws/js/jquery/3.5.1/jquery.min.js"></script>
    <!-- Latest compiled and minified JavaScript -->
    <script src="https://assets.opendata.aws/js/bootstrap/3.4.1/bootstrap.min.js"></script>
    <nav class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <div class="roda-header">
          <h2><a href="/" alt="Home">Registry of Open Data on AWS</a></h2>
          <a href="http://aws.amazon.com/what-is-cloud-computing">
            <img src="https://assets.opendata.aws/img/AWS-Logo_White-Color_300x180.png" alt="Powered by AWS Cloud Computing" id="aws_header_logo">
          </a>
        </div>
      </div>
    </nav>
    <div class="container" >

    <div class="about col-md-5">
      <div class="row aboutbox">
            <h3>About</h3>
            <p>This registry exists to help people discover and share datasets that are available via AWS resources. <a href="https://opendata.aws">Learn more about sharing data on AWS</a>.</p>
    
            <p>See <a href="/tag/deep-learning/usage-examples">all usage examples for datasets listed in this registry</a> tagged with <strong>deep learning</strong>.</p>
    
        <hr>
    
        <h4>Search datasets (currently <span id="count-matching">13</span> matching <span id="count-matching-text">datasets</span>)</h4>
        <form>
          <div class="form-group">
            <input type="text" id="search-box" class="form-control" placeholder="Search datasets" spellcheck="false" autocorrect="off">
          </div>
        </form>
        <p>You are currently viewing a subset of data tagged with <strong>deep learning</strong>.</p>
    
        <hr>
    
        <h4>Add to this registry</h4>
        <p>If you want to add a dataset or example of how to use a dataset to this registry, please follow the instructions on the <a href="https://github.com/awslabs/open-data-registry/">Registry of Open Data on AWS GitHub repository</a>.</p>
    
        <p>Unless specifically stated in the applicable dataset documentation, datasets available through the Registry of Open Data on AWS are not provided and maintained by AWS. Datasets are provided and maintained by a variety of third parties under a variety of licenses. Please check dataset licenses and related documentation to determine if a dataset may be used for your application.</p>
      </div>
    </div>
    <div class="col-md-6 col-md-offset-1 datasets">
      <div class="row">
        <div id="encode-project" class="dataset">
          <h3><a href="/encode-project/">Encyclopedia of DNA Elements (ENCODE)</a></h3>
          <p><span class="label label-info tag link-tag">bioinformatics</span><span class="label label-info tag link-tag">biology</span><span class="label label-info tag link-tag">deep learning</span><span class="label label-info tag link-tag">genetic</span><span class="label label-info tag link-tag">genomic</span><span class="label label-info tag link-tag">life sciences</span><span class="label label-info tag link-tag">machine learning</span></p>
          <p>The Encyclopedia of DNA Elements (ENCODE) Consortium is an international collaboration of
research groups funded by the National Human Genome Research Institute (NHGRI). The goal
of ENCODE is to build a comprehensive parts list of functional elements in the human genome,
including elements that act at the protein and RNA levels, and regulatory elements that
control cells and circumstances in which a gene is active. ENCODE investigators employ a
variety of assays and methods to identify functional elements. The discovery and annotation
of gene elements is accomplished primarily by sequencing a ...</p>
          <p><a href="/encode-project/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://academic.oup.com/nar/article/48/D1/D882/5622708#190992715" class="" target="_none">New developments on the Encyclopedia of DNA Elements (ENCODE) data portal</a> by <a href="http://orcid.org/0000-0001-6948-2042" target="_none">Luo et al 2020</a></li></a>
          </li>
          <li>
            <a href="https://github.com/ENCODE-DCC/encode-data-usage-examples/blob/master/ctcf_chip_seq_cross_cell_type_correlation.ipynb" class="" target="_none">ENCODE CTCF ChIP-seq data correlation across different cell types</a> by <a href="https://github.com/p-sud" target="_none">Paul Sud</a></li></a>
          </li>
          <li>
            <a href="https://github.com/ENCODE-DCC/encode-data-usage-examples/blob/master/ingest_encode_data_tile_db_with_s3_backend.ipynb" class="" target="_none">Ingesting ENCODE data into TileDB with S3 backend</a> by <a href="https://github.com/ottojolanki" target="_none">Otto Jolanki</a></li></a>
          </li>
          <li>
            <a href="https://github.com/ENCODE-DCC/encode-data-usage-examples/blob/master/mount_s3_bucket_and_run_jupyter_on_ec2.ipynb" class="" target="_none">Exploring ENCODE data from EC2 with Jupyter notebook</a> by <a href="https://github.com/keenangraham" target="_none">Keenan Graham</a></li></a>
          </li>
        </ul>
        <p><a href="/encode-project/#usageexamples">See 4 usage examples &rarr;</a></p>
        </div>
        <div id="grillo-openeew" class="dataset">
          <h3><a href="/grillo-openeew/">OpenEEW</a></h3>
          <p><span class="label label-info tag link-tag">deep learning</span><span class="label label-info tag link-tag">disaster response</span><span class="label label-info tag link-tag">earth observation</span><span class="label label-info tag link-tag">earthquakes</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info-sustainability tag link-tag">sustainability</span></p>
          <p>Grillo has developed an IoT-based earthquake early-warning system,
with sensors currently deployed in Mexico, Chile, Puerto Rico and Costa Rica,
and is now opening its entire archive of unprocessed accelerometer
data to the world to encourage the development of new algorithms
capable of rapidly detecting and characterizing earthquakes in
real time.</p>
          <p><a href="/grillo-openeew/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://openeew.com/docs/analyze-historic" class="" target="_none">Analyzing a magnitude 7.2 earthquake in Mexico using Python</a> by <a href="https://grillo.io/" target="_none">Grillo</a></li></a>
          </li>
          <li>
            <a href="https://github.com/openeew/openeew-python" class="" target="_none">OpenEEW library for Python</a> by <a href="https://grillo.io/" target="_none">Grillo</a></li></a>
          </li>
          <li>
            <a href="https://openeew.com/docs/machine-learning" class="" target="_none">Developing a machine learning model for better earthquake detection</a> by <a href="https://grillo.io/" target="_none">Grillo</a></li></a>
          </li>
        </ul>
        <p><a href="/grillo-openeew/#usageexamples">See 3 usage examples &rarr;</a></p>
        </div>
        <div id="sorel-20m" class="dataset">
          <h3><a href="/sorel-20m/">Sophos/ReversingLabs 20 Million malware detection dataset</a></h3>
          <p><span class="label label-info tag link-tag">cyber security</span><span class="label label-info tag link-tag">deep learning</span><span class="label label-info tag link-tag">labeled</span><span class="label label-info tag link-tag">machine learning</span></p>
          <p>A dataset intended to support research on machine learning
techniques for detecting malware.  It includes metadata and EMBER-v2
features for approximately 10 million benign and 10 million malicous
Portable Executable files, with disarmed but otherwise complete
files for all malware samples.  All samples are labeled using Sophos
in-house labeling methods, have features extracted using the
EMBER-v2 feature set, well as metadata obtained via the pefile
python library, detection counts obtained via ReversingLabs
telemetry, and additional behavioral tags that indicate the rough
behavior of the samp...</p>
          <p><a href="/sorel-20m/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://github.com/sophos-ai/SOREL-20M" class="" target="_none">SOREL-20M dataset interface code</a> by Richard Harang and Ethan M Rudd</li></a>
          </li>
          <li>
            <a href="https://github.com/sophos-ai/SOREL-20M#quickstart" class="" target="_none">SOREL-20M quickstart</a> by Richard Harang</li></a>
          </li>
          <li>
            <a href="https://arxiv.org/abs/2012.07634" class="" target="_none">SOREL-20M: A Large Scale Benchmark Dataset for Malicious PE Detection
</a> by Richard Harang and Ethan M Rudd</li></a>
          </li>
        </ul>
        <p><a href="/sorel-20m/#usageexamples">See 3 usage examples &rarr;</a></p>
        </div>
        <div id="rareplanes" class="dataset">
          <h3><a href="/rareplanes/">RarePlanes</a></h3>
          <p><span class="label label-info tag link-tag">computer vision</span><span class="label label-info tag link-tag">deep learning</span><span class="label label-info tag link-tag">earth observation</span><span class="label label-info tag link-tag">geospatial</span><span class="label label-info tag link-tag">labeled</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">satellite imagery</span></p>
          <p>RarePlanes is a unique open-source machine learning dataset from CosmiQ Works and AI.Reverie that incorporates both real and synthetically generated satellite imagery. The RarePlanes dataset specifically focuses on the value of AI.Reverie synthetic data to aid computer vision algorithms in their ability to automatically detect aircraft and their attributes in satellite imagery. Although other synthetic/real combination datasets exist, RarePlanes is the largest openly-available very high resolution dataset built to test the value of synthetic data from an overhead perspective. The real portion ...</p>
          <p><a href="/rareplanes/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://arxiv.org/abs/2006.02963" class="" target="_none">RarePlanes: Synthetic Data Takes Flight</a> by Jacob Shermeyer, Thomas Hossler, Adam Van Etten, Daniel Hogan, Ryan Lewis, Daeil Kim</li></a>
          </li>
          <li>
            <a href="https://github.com/aireveries/RarePlanes" class="" target="_none">RarePlanes Codebase</a> by Thomas Hossler and Jacob Shermeyer</li></a>
          </li>
        </ul>
        <p><a href="/rareplanes/#usageexamples">See 2 usage examples &rarr;</a></p>
        </div>
        <div id="asr-error-robustness" class="dataset">
          <h3><a href="/asr-error-robustness/">Automatic Speech Recognition (ASR) Error Robustness</a></h3>
          <p><span class="label label-info tag link-tag">deep learning</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">natural language processing</span><span class="label label-info tag link-tag">speech recognition</span></p>
          <p>Sentence classification datatasets with ASR Errors.</p>
          <p><a href="/asr-error-robustness/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://assets.amazon.science/64/94/639ae0c44890837b0f1fbf11ef77/using-phoneme-representations-to-build-predictive-models-robust-to-asr-errors.pdf" class="" target="_none">Using Phoneme Representations to Build Predictive Models Robust to ASR Errors</a> by <a href="https://anjiefang.github.io" target="_none">Anjie Fang, Simone Filice, Nut Limsopatham and Oleg Rokhlenko</a></li></a>
          </li>
        </ul>
        <p><a href="/asr-error-robustness/#usageexamples">See 1 usage example &rarr;</a></p>
        </div>
        <div id="aev-a2d2" class="dataset">
          <h3><a href="/aev-a2d2/">A2D2: Audi Autonomous Driving Dataset</a></h3>
          <p><span class="label label-info tag link-tag">autonomous vehicles</span><span class="label label-info tag link-tag">computer vision</span><span class="label label-info tag link-tag">deep learning</span><span class="label label-info tag link-tag">lidar</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">mapping</span><span class="label label-info tag link-tag">robotics</span></p>
          <p>An open multi-sensor dataset for autonomous driving research. This dataset comprises semantically segmented images, semantic point clouds, and 3D bounding boxes. In addition, it contains unlabelled 360 degree camera images, lidar, and bus data for three sequences. We hope this dataset will further facilitate active research and development in AI, computer vision, and robotics for autonomous driving.</p>
          <p><a href="/aev-a2d2/">Details &rarr;</a></p>
        </div>
        <div id="fast-ai-coco" class="dataset">
          <h3><a href="/fast-ai-coco/">COCO - Common Objects in Context - fast.ai datasets</a></h3>
          <p><span class="label label-info tag link-tag">computer vision</span><span class="label label-info tag link-tag">deep learning</span><span class="label label-info tag link-tag">machine learning</span></p>
          <p>COCO is a large-scale object detection, segmentation, and captioning dataset.
This is part of the fast.ai datasets collection hosted by AWS for convenience
of fast.ai students. If you use this dataset in your research please cite
arXiv:1405.0312 [cs.CV].</p>
          <p><a href="/fast-ai-coco/">Details &rarr;</a></p>
        </div>
        <div id="fast-ai-imageclas" class="dataset">
          <h3><a href="/fast-ai-imageclas/">Image classification - fast.ai datasets</a></h3>
          <p><span class="label label-info tag link-tag">computer vision</span><span class="label label-info tag link-tag">deep learning</span><span class="label label-info tag link-tag">machine learning</span></p>
          <p>Some of the most important datasets for image classification research, including
CIFAR 10 and 100, Caltech 101, MNIST, Food-101, Oxford-102-Flowers, Oxford-IIIT-Pets,
and Stanford-Cars.  This is part of the fast.ai datasets collection hosted by
AWS for convenience of fast.ai students. See documentation link for citation and
license details for each dataset.</p>
          <p><a href="/fast-ai-imageclas/">Details &rarr;</a></p>
        </div>
        <div id="fast-ai-imagelocal" class="dataset">
          <h3><a href="/fast-ai-imagelocal/">Image localization  - fast.ai datasets</a></h3>
          <p><span class="label label-info tag link-tag">computer vision</span><span class="label label-info tag link-tag">deep learning</span><span class="label label-info tag link-tag">machine learning</span></p>
          <p>Some of the most important datasets for image localization  research, including
Camvid and PASCAL VOC (2007 and 2012). This is part of the fast.ai datasets
collection hosted by AWS for convenience of fast.ai students. See
documentation link for citation and license details for each dataset.</p>
          <p><a href="/fast-ai-imagelocal/">Details &rarr;</a></p>
        </div>
        <div id="kitti" class="dataset">
          <h3><a href="/kitti/">KITTI Vision Benchmark Suite</a></h3>
          <p><span class="label label-info tag link-tag">autonomous vehicles</span><span class="label label-info tag link-tag">computer vision</span><span class="label label-info tag link-tag">deep learning</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">robotics</span></p>
          <p>Dataset and benchmarks for computer vision research in the context of autonomous driving. The dataset has been recorded in and around the city of Karlsruhe, Germany using the mobile platform AnnieWay (VW station wagon) which has been equipped with several RGB and monochrome cameras, a Velodyne HDL 64 laser scanner as well as an accurate RTK corrected GPS/IMU localization unit. The dataset has been created for computer vision and machine learning research on stereo, optical flow, visual odometry, semantic segmentation, semantic instance segmentation, road segmentation, single image depth predic...</p>
          <p><a href="/kitti/">Details &rarr;</a></p>
        </div>
        <div id="fast-ai-nlp" class="dataset">
          <h3><a href="/fast-ai-nlp/">NLP - fast.ai datasets</a></h3>
          <p><span class="label label-info tag link-tag">deep learning</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">natural language processing</span></p>
          <p>Some of the most important datasets for NLP, with a focus on classification, including
IMDb, AG-News, Amazon Reviews (polarity and full), Yelp Reviews (polarity and
full), Dbpedia, Sogou News (Pinyin), Yahoo Answers, Wikitext 2 and Wikitext
103, and ACL-2010 French-English 10^9 corpus.  This is part of the
fast.ai datasets collection hosted by AWS for convenience of fast.ai
students. See documentation link for citation and license details for each
dataset.</p>
          <p><a href="/fast-ai-nlp/">Details &rarr;</a></p>
        </div>
        <div id="agriculture_vision" class="dataset">
          <h3><a href="/agriculture_vision/">AgricultureVision</a></h3>
          <p><span class="label label-info tag link-tag">aerial imagery</span><span class="label label-info tag link-tag">agriculture</span><span class="label label-info tag link-tag">computer vision</span><span class="label label-info tag link-tag">deep learning</span></p>
          <p>Dataset associated with the paper &quot;Agriculture-Vision: A Large Aerial Image Database for Agricultural Pattern Analysis&quot;. Agriculture-Vision aims to be a publicly available large-scale aerial agricultural image dataset that is high-resolution, multi-band, and with multiple types of patterns annotated by agronomy experts. In its current stage, we have captured 94,986 512x512images sampled from 3,432 farmlands with nine types of annotations: double plant, drydown, endrow, nutrient deficiency, planter skip, storm damage, water, waterway and weed cluster. All of these patterns have substa...</p>
          <p><a href="/agriculture_vision/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://arxiv.org/abs/2001.01306" class="" target="_none">Agriculture-Vision: A Large Aerial Image Database for Agricultural Pattern Analysis</a> by Mang Tik Chiu, et al.</li></a>
          </li>
        </ul>
        <p><a href="/agriculture_vision/#usageexamples">See 1 usage example &rarr;</a></p>
        </div>
      </div>
    </div>


    <hr/>
  </div>  </body>
  <script src="/js/index.js"></script>
</html>
