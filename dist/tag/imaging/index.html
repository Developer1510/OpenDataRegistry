<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
  
    
  
    <link rel="alternate" type="application/rss+xml" href="/rss.xml" />
    
    <link rel="shortcut icon" type="image/ico" href="https://a0.awsstatic.com/libra-css/images/site/fav/favicon.ico"/>
    <link rel="apple-touch-icon" sizes="57x57" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-iphone-114-smile.png"/>
    <link rel="apple-touch-icon" sizes="72x72" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-ipad-144-smile.png"/>
    <link rel="apple-touch-icon" sizes="114x114" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-iphone-114-smile.png"/>
    <link rel="apple-touch-icon" sizes="144x144" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-ipad-144-smile.png"/>  
  
    <title>Registry of Open Data on AWS</title>
  
    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://assets.opendata.aws/css/bootstrap/3.4.1/bootstrap.min.css">
  
    <!-- Our local CSS -->
    <link rel="stylesheet" href="/css/main.css">
  
  
  </head>
  <body>
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://assets.opendata.aws/js/jquery/3.5.1/jquery.min.js"></script>
    <!-- Latest compiled and minified JavaScript -->
    <script src="https://assets.opendata.aws/js/bootstrap/3.4.1/bootstrap.min.js"></script>
    <nav class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <div class="roda-header">
          <h2><a href="/" alt="Home">Registry of Open Data on AWS</a></h2>
          <a href="http://aws.amazon.com/what-is-cloud-computing">
            <img src="https://assets.opendata.aws/img/AWS-Logo_White-Color_300x180.png" alt="Powered by AWS Cloud Computing" id="aws_header_logo">
          </a>
        </div>
      </div>
    </nav>
    <div class="container" >

    <div class="about col-md-5">
      <div class="row aboutbox">
            <h3>About</h3>
            <p>This registry exists to help people discover and share datasets that are available via AWS resources. <a href="https://opendata.aws">Learn more about sharing data on AWS</a>.</p>
    
            <p>See <a href="/tag/imaging/usage-examples">all usage examples for datasets listed in this registry</a> tagged with <strong>imaging</strong>.</p>
    
        <hr>
    
        <h4>Search datasets (currently <span id="count-matching">13</span> matching <span id="count-matching-text">datasets</span>)</h4>
        <form>
          <div class="form-group">
            <input type="text" id="search-box" class="form-control" placeholder="Search datasets" spellcheck="false" autocorrect="off">
          </div>
        </form>
        <p>You are currently viewing a subset of data tagged with <strong>imaging</strong>.</p>
    
        <hr>
    
        <h4>Add to this registry</h4>
        <p>If you want to add a dataset or example of how to use a dataset to this registry, please follow the instructions on the <a href="https://github.com/awslabs/open-data-registry/">Registry of Open Data on AWS GitHub repository</a>.</p>
    
        <p>Unless specifically stated in the applicable dataset documentation, datasets available through the Registry of Open Data on AWS are not provided and maintained by AWS. Datasets are provided and maintained by a variety of third parties under a variety of licenses. Please check dataset licenses and related documentation to determine if a dataset may be used for your application.</p>
      </div>
    </div>
    <div class="col-md-6 col-md-offset-1 datasets">
      <div class="row">
        <div id="cbers" class="dataset">
          <h3><a href="/cbers/">CBERS on AWS</a></h3>
          <p><span class="label label-info tag link-tag">agriculture</span><span class="label label-info tag link-tag">disaster response</span><span class="label label-info tag link-tag">earth observation</span><span class="label label-info tag link-tag">geospatial</span><span class="label label-info tag link-tag">imaging</span><span class="label label-info tag link-tag">satellite imagery</span><span class="label label-info-sustainability tag link-tag">sustainability</span></p>
          <p>This project creates a S3 repository with imagery acquired
by the China-Brazil Earth Resources Satellite (CBERS). The
image files are recorded and processed by Instituto Nacional de Pesquisa
Espaciais (INPE) and are converted to Cloud Optimized Geotiff
format in order to optimize its use for cloud based applications.
The repository contains all CBERS-4 MUX, AWFI, PAN5M and
PAN10M scenes acquired since
the start of the satellite mission and is daily updated with
new scenes.</p>
          <p><a href="/cbers/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://viewer.remotepixel.ca" class="" target="_none">Remote Pixel Viewer</a> by <a href="http://remotepixel.ca/" target="_none">Remote Pixel</a></li></a>
          </li>
          <li>
            <a href="https://aws.amazon.com/blogs/publicsector/keeping-a-spatiotemporal-asset-catalog-stac-up-to-date-with-sns-sqs/" class="aws-link" target="_none">Keeping a SpatioTemporal Asset Catalog (STAC) Up To Date with SNS/SQS</a> by Frederico Liporace</li></a>
          </li>
          <li>
            <a href="https://eos.com/landviewer/" class="" target="_none">EOS Land Viewer</a> by <a href="https://eos.com/" target="_none">Earth Observing System</a></li></a>
          </li>
          <li>
            <a href="https://github.com/fredliporace/cbersgif" class="" target="_none">CBERS timelapse GIF generator</a> by <a href="https://github.com/fredliporace" target="_none">Frederico Liporace</a></li></a>
          </li>
          <li>
            <a href="https://stac.amskepler.com/v10/stac/search" class="" target="_none">STAC V1.0 search endpoint for archive</a> by <a href="https://github.com/fredliporace/cbers-2-stac" target="_none">AMS Kepler</a></li></a>
          </li>
        </ul>
        <p><a href="/cbers/#usageexamples">See 11 usage examples &rarr;</a></p>
        </div>
        <div id="ladi" class="dataset">
          <h3><a href="/ladi/">Low Altitude Disaster Imagery (LADI) Dataset</a></h3>
          <p><span class="label label-info tag link-tag">aerial imagery</span><span class="label label-info tag link-tag">coastal</span><span class="label label-info tag link-tag">computer vision</span><span class="label label-info tag link-tag">disaster response</span><span class="label label-info tag link-tag">earth observation</span><span class="label label-info tag link-tag">earthquakes</span><span class="label label-info tag link-tag">geospatial</span><span class="label label-info tag link-tag">image processing</span><span class="label label-info tag link-tag">imaging</span><span class="label label-info tag link-tag">infrastructure</span><span class="label label-info tag link-tag">land</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">mapping</span><span class="label label-info tag link-tag">natural resource</span><span class="label label-info tag link-tag">seismology</span><span class="label label-info tag link-tag">transportation</span><span class="label label-info tag link-tag">urban</span><span class="label label-info tag link-tag">water</span></p>
          <p>The Low Altitude Disaster Imagery (LADI) Dataset consists of human and machine annotated airborne images collected by the Civil Air Patrol in support of various disaster responses from 2015-2019. The initial release of LADI focuses on the Atlantic hurricane seasons and coastal states along the Atlantic Ocean and Gulf of Mexico. Annotations are included for major hurricanes of Harvey, Maria, and Florence. Two key distinctions are the low altitude, oblique perspective of the imagery and disaster-related features, which are rarely featured in computer vision benchmarks and datasets.</p>
          <p><a href="/ladi/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://github.com/LADI-Dataset/ladi-tutorial" class="" target="_none">LADI Tutorials</a> by <a href="https://github.com/LADI-Dataset" target="_none">Andrew Weinert, Jianyu Mao, Kiana Harris, Nae-Rong Chang, Caleb Pennell, Yiming Ren, Ryan Earley, Nadia Dimitrova</a></li></a>
          </li>
          <li>
            <a href="https://doi.org/10.1109/LNET.2019.2955833" class="" target="_none">Video Testing at the FirstNet Innovation and Test Lab Using a Public Safety Dataset</a> by Chris Budny, Jeffrey Liu, Andrew Weinert</li></a>
          </li>
          <li>
            <a href="https://doi.org/10.1109/HPEC.2019.8916437" class="" target="_none">Large Scale Organization and Inference of an Imagery Dataset for Public Safety</a> by Jeffrey Liu, David Strohschein, Siddharth Samsi, Andrew Weinert</li></a>
          </li>
          <li>
            <a href="https://github.com/bwsi-hadr" class="" target="_none">Remote Sensing for Disaster Response Course</a> by <a href="https://beaverworks.ll.mit.edu/CMS/bw/bwsi" target="_none">Beaver Works Summer Institute</a></li></a>
          </li>
          <li>
            <a href="https://www-nlpir.nist.gov/projects/tv2020/dsdi.html" class="" target="_none">NIST TRECVID 2020 - Disaster Scene Description and Indexing (DSDI)</a> by TREC Video Retrieval Evaluation (TRECVID)</li></a>
          </li>
        </ul>
        <p><a href="/ladi/#usageexamples">See 6 usage examples &rarr;</a></p>
        </div>
        <div id="allen-mouse-brain-atlas" class="dataset">
          <h3><a href="/allen-mouse-brain-atlas/">Allen Mouse Brain Atlas</a></h3>
          <p><span class="label label-info tag link-tag">biology</span><span class="label label-info tag link-tag">gene expression</span><span class="label label-info tag link-tag">genetic</span><span class="label label-info tag link-tag">image processing</span><span class="label label-info tag link-tag">imaging</span><span class="label label-info tag link-tag">life sciences</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">Mus musculus</span><span class="label label-info tag link-tag">neurobiology</span><span class="label label-info tag link-tag">transcriptomics</span></p>
          <p>The Allen Mouse Brain Atlas is a genome-scale collection of cellular resolution gene expression profiles using in situ hybridization (ISH). Highly methodical data production methods and comprehensive anatomical coverage via dense, uniformly spaced sampling facilitate data consistency and comparability across &gt;20,000 genes. The use of an inbred mouse strain with minimal animal-to-animal variance allows one to treat the brain essentially as a complex but highly reproducible three-dimensional tissue array. The entire Allen Mouse Brain Atlas dataset and associated tools are available through an...</p>
          <p><a href="/allen-mouse-brain-atlas/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="http://www.nature.com/articles/nature05453" class="" target="_none">Genome-wide atlas of gene expression in the adult mouse brain</a> by <a href="www.alleninstitute.org" target="_none">Ed Lein, et al.</a></li></a>
          </li>
          <li>
            <a href="https://mouse.brain-map.org" class="" target="_none">Allen Mouse Brain Atlas</a> by <a href="www.alleninstitute.org" target="_none">Allen Institute for Brain Science</a></li></a>
          </li>
          <li>
            <a href="https://github.com/AllenInstitute/open_dataset_tools/blob/master/Visualizing_Images_from_Allen_Mouse_Brain_Atlas.ipynb" class="" target="_none">Visualizing Images from the Allen Mouse Brain Atlas</a> by <a href="www.alleninstitute.org" target="_none">Allen Institute for Brain Science</a></li></a>
          </li>
        </ul>
        <p><a href="/allen-mouse-brain-atlas/#usageexamples">See 3 usage examples &rarr;</a></p>
        </div>
        <div id="msd" class="dataset">
          <h3><a href="/msd/">Medical Segmentation Decathlon</a></h3>
          <p><span class="label label-info tag link-tag">computed tomography</span><span class="label label-info tag link-tag">health</span><span class="label label-info tag link-tag">imaging</span><span class="label label-info tag link-tag">life sciences</span><span class="label label-info tag link-tag">magnetic resonance imaging</span><span class="label label-info tag link-tag">medicine</span><span class="label label-info tag link-tag">nifti</span><span class="label label-info tag link-tag">segmentation</span></p>
          <p>With recent advances in machine learning, semantic segmentation algorithms are becoming increasingly general purpose and translatable to unseen tasks. Many key algorithmic advances in the field of medical imaging are commonly validated on a small number of tasks, limiting our understanding of the generalisability of the proposed contributions. A model which works out-of-the-box on many tasks, in the spirit of AutoML, would have a tremendous impact on healthcare. The field of medical imaging is also missing a fully open source and comprehensive benchmark for general purpose algorithmic validati...</p>
          <p><a href="/msd/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://arxiv.org/pdf/1902.09063.pdf" class="" target="_none">A large annotated medical image dataset for the development and evaluation of segmentation algorithms</a> by Simpson A. L., Antonelli M., Bakas S., Bilello M., Farahana K., van Ginneken B., et al</li></a>
          </li>
          <li>
            <a href="www.monai.io" class="" target="_none">MONAI: Getting Started</a> by <a href="https://monai.io/start.html" target="_none">MONAI Development Team</a></li></a>
          </li>
          <li>
            <a href="https://github.com/Project-MONAI/tutorials" class="" target="_none">Pytorch-Integrated MSD Data Loader</a> by <a href="https://github.com/Project-MONAI/MONAI" target="_none">MONAI Development Team</a></li></a>
          </li>
        </ul>
        <p><a href="/msd/#usageexamples">See 3 usage examples &rarr;</a></p>
        </div>
        <div id="digitalcorpora" class="dataset">
          <h3><a href="/digitalcorpora/">DigitalCorpora</a></h3>
          <p><span class="label label-info tag link-tag">computer forensics</span><span class="label label-info tag link-tag">computer security</span><span class="label label-info tag link-tag">CSI</span><span class="label label-info tag link-tag">cyber security</span><span class="label label-info tag link-tag">digital forensics</span><span class="label label-info tag link-tag">image processing</span><span class="label label-info tag link-tag">imaging</span><span class="label label-info tag link-tag">information retrieval</span><span class="label label-info tag link-tag">internet</span><span class="label label-info tag link-tag">intrusion detection</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">machine translation</span><span class="label label-info tag link-tag">text analysis</span></p>
          <p>Disk images, memory dumps, network packet captures, and files for use in digital forensics research and education. All of this information is accessible through the digitalcorpora.org website, and made available at s3://digitalcorpora/. Some of these datasets implement scenarios that were performed by students, faculty, and others acting <em>in persona</em>. As such, the information is synthetic and may be used without prior authorization or IRB approval. Details of these datasets can be found at <a href="http://www.simson.net/clips/academic/2009...</p>
          <p><a href="/digitalcorpora/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="http://simson.net/clips/academic/2011.ADFSL.Corpora.pdf" class="" target="_none">Creating Realistic Corpora for Forensic and Security Education</a> by <a href="https://simson.net/" target="_none">Woods, K., Christopher Lee, Simson Garfinkel, David Dittrich, Adam Russel, Kris Kearton</a></li></a>
          </li>
          <li>
            <a href="http://www.simson.net/clips/academic/2009.DFRWS.Corpora.pdf" class="" target="_none">Bringing Science to Digital Forensics with Standardized Forensic Corpora</a> by <a href="https://simson.net/" target="_none">Garfinkel, Farrell, Roussev and Dinolt</a></li></a>
          </li>
        </ul>
        <p><a href="/digitalcorpora/#usageexamples">See 2 usage examples &rarr;</a></p>
        </div>
        <div id="lofar-elais-n1" class="dataset">
          <h3><a href="/lofar-elais-n1/">LOFAR ELAIS-N1 cycle 2 observations on AWS</a></h3>
          <p><span class="label label-info tag link-tag">astronomy</span><span class="label label-info tag link-tag">imaging</span><span class="label label-info tag link-tag">survey</span></p>
          <p>These data correspond to the <a href="http://www.lofar.org/">International LOFAR Telescope</a> observations of the sky field ELAIS-N1 (16:10:01 +54:30:36) during the cycle 2 of observations. There are 11 runs of about 8 hours each plus the corresponding observation of the calibration targets before and after the target field. The data are measurement sets (<a href="https://casa.nrao.edu/Memos/229.html">MS</a>) containing the cross-correlated data and metadata divided in 371 frequency sub-bands per target centred at ~150 MHz.</p>
          <p><a href="/lofar-elais-n1/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://www.lofarcloud.uk" class="" target="_none">Calibration of LOFAR ELAIS-N1 data in the Amazon cloud</a> by <a href="https://github.com/nudomarinero" target="_none">J. Sabater</a></li></a>
          </li>
        </ul>
        <p><a href="/lofar-elais-n1/#usageexamples">See 1 usage example &rarr;</a></p>
        </div>
        <div id="nj-imagery" class="dataset">
          <h3><a href="/nj-imagery/">New Jersey Statewide Digital Aerial Imagery Catalog</a></h3>
          <p><span class="label label-info tag link-tag">aerial imagery</span><span class="label label-info tag link-tag">earth observation</span><span class="label label-info tag link-tag">geospatial</span><span class="label label-info tag link-tag">imaging</span><span class="label label-info tag link-tag">mapping</span></p>
          <p>The New Jersey Office of GIS, NJ Office of Information Technology manages a series of 11 digital orthophotography and scanned aerial photo maps collected at various years ranging from 1930 to 2017. Each year’s worth of imagery are available as Cloud Optimized GeoTIFF (COG) files and some years are available as compressed MrSID and/or JP2 files.  Additionally, each year of imagery is organized into a tile grid scheme covering the entire geography of New Jersey.  Many years share the same tiling grid while others have unique grids as defined by the project at the time.</p>
          <p><a href="/nj-imagery/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://njogis-imagery.s3-us-west-2.amazonaws.com/NJ+Imagery+Change.pdf" class="" target="_none">Visualize Imagery Changes</a> by <a href="https://njgin.nj.gov/njgin/edata/imagery/index.html" target="_none">stephanie.bosits@tech.nj.gov</a></li></a>
          </li>
        </ul>
        <p><a href="/nj-imagery/#usageexamples">See 1 usage example &rarr;</a></p>
        </div>
        <div id="ocmr_data" class="dataset">
          <h3><a href="/ocmr_data/">Ohio State Cardiac MRI Raw Data (OCMR)</a></h3>
          <p><span class="label label-info tag link-tag">Homo sapiens</span><span class="label label-info tag link-tag">image processing</span><span class="label label-info tag link-tag">imaging</span><span class="label label-info tag link-tag">life sciences</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">magnetic resonance imaging</span><span class="label label-info tag link-tag">signal processing</span></p>
          <p>OCMR is an open-access repository that provides multi-coil k-space data for cardiac cine.  The fully sampled MRI datasets are intended for quantitative comparison and evaluation of image reconstruction methods. The free-breathing, prospectively undersampled datasets are intended to evaluate their performance and generalizability qualitatively.</p>
          <p><a href="/ocmr_data/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://github.com/MRIOSU/OCMR/blob/master/Python/example_ocmr.ipynb" class="" target="_none">OCMR Tutorial</a> by <a href="https://cmr.engineering.osu.edu/people/trainees" target="_none">Chong Chen</a></li></a>
          </li>
        </ul>
        <p><a href="/ocmr_data/#usageexamples">See 1 usage example &rarr;</a></p>
        </div>
        <div id="xiph-media" class="dataset">
          <h3><a href="/xiph-media/">Xiph.Org Test Media</a></h3>
          <p><span class="label label-info tag link-tag">computer vision</span><span class="label label-info tag link-tag">image processing</span><span class="label label-info tag link-tag">imaging</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">media</span><span class="label label-info tag link-tag">movies</span><span class="label label-info tag link-tag">multimedia</span></p>
          <p>Uncompressed video used for video compression and video processing research.</p>
          <p><a href="/xiph-media/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://media.xiph.org/aws.html" class="" target="_none">Encoding video with AV1 on EC2</a> by <a href="https://www.xiph.org/" target="_none">Thomas Daede</a></li></a>
          </li>
        </ul>
        <p><a href="/xiph-media/#usageexamples">See 1 usage example &rarr;</a></p>
        </div>
        <div id="openneuro" class="dataset">
          <h3><a href="/openneuro/">OpenNeuro</a></h3>
          <p><span class="label label-info tag link-tag">biology</span><span class="label label-info tag link-tag">imaging</span><span class="label label-info tag link-tag">life sciences</span><span class="label label-info tag link-tag">neurobiology</span><span class="label label-info tag link-tag">neuroimaging</span></p>
          <p>OpenNeuro is a database of openly-available brain imaging data. The data are shared according to a Creative Commons CC0 license, providing a broad range of brain imaging data to researchers and citizen scientists alike. The database primarily focuses on functional magnetic resonance imaging (fMRI) data, but also includes other imaging modalities including structural and diffusion MRI, electroencephalography (EEG), and magnetoencephalograpy (MEG). OpenfMRI is a project of the <a href="http://reproducibility.stanford.edu">Center for Reproducible Neuroscience at Stanford University</a>. Development of the OpenNeuro resource has been funded by th...</p>
          <p><a href="/openneuro/">Details &rarr;</a></p>
        </div>
      </div>
    </div>


    <hr/>
  </div>  </body>
  <script src="/js/index.js"></script>
</html>
