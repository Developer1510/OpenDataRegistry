<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
  
    
  
    <link rel="alternate" type="application/rss+xml" href="/rss.xml" />
    
    <link rel="shortcut icon" type="image/ico" href="https://a0.awsstatic.com/libra-css/images/site/fav/favicon.ico"/>
    <link rel="apple-touch-icon" sizes="57x57" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-iphone-114-smile.png"/>
    <link rel="apple-touch-icon" sizes="72x72" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-ipad-144-smile.png"/>
    <link rel="apple-touch-icon" sizes="114x114" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-iphone-114-smile.png"/>
    <link rel="apple-touch-icon" sizes="144x144" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-ipad-144-smile.png"/>  
  
    <title>Registry of Open Data on AWS</title>
  
    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://assets.opendata.aws/css/bootstrap/3.4.1/bootstrap.min.css">
  
    <!-- Our local CSS -->
    <link rel="stylesheet" href="/css/main.css">
  
  
  </head>
  <body>
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://assets.opendata.aws/js/jquery/3.5.1/jquery.min.js"></script>
    <!-- Latest compiled and minified JavaScript -->
    <script src="https://assets.opendata.aws/js/bootstrap/3.4.1/bootstrap.min.js"></script>
    <nav class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <div class="roda-header">
          <h2><a href="/" alt="Home">Registry of Open Data on AWS</a></h2>
          <a href="http://aws.amazon.com/what-is-cloud-computing">
            <img src="https://assets.opendata.aws/img/AWS-Logo_White-Color_300x180.png" alt="Powered by AWS Cloud Computing" id="aws_header_logo">
          </a>
        </div>
      </div>
    </nav>
    <div class="container" >

    <div class="about col-md-5">
      <div class="row aboutbox">
            <h3>About</h3>
            <p>This registry exists to help people discover and share datasets that are available via AWS resources. <a href="https://opendata.aws">Learn more about sharing data on AWS</a>.</p>
    
            <p>See <a href="/tag/urban/usage-examples">all usage examples for datasets listed in this registry</a> tagged with <strong>urban</strong>.</p>
    
        <hr>
    
        <h4>Search datasets (currently <span id="count-matching">13</span> matching <span id="count-matching-text">datasets</span>)</h4>
        <form>
          <div class="form-group">
            <input type="text" id="search-box" class="form-control" placeholder="Search datasets" spellcheck="false" autocorrect="off">
          </div>
        </form>
        <p>You are currently viewing a subset of data tagged with <strong>urban</strong>.</p>
    
        <hr>
    
        <h4>Add to this registry</h4>
        <p>If you want to add a dataset or example of how to use a dataset to this registry, please follow the instructions on the <a href="https://github.com/awslabs/open-data-registry/">Registry of Open Data on AWS GitHub repository</a>.</p>
    
        <p>Unless specifically stated in the applicable dataset documentation, datasets available through the Registry of Open Data on AWS are not provided and maintained by AWS. Datasets are provided and maintained by a variety of third parties under a variety of licenses. Please check dataset licenses and related documentation to determine if a dataset may be used for your application.</p>
      </div>
    </div>
    <div class="col-md-6 col-md-offset-1 datasets">
      <div class="row">
        <div id="ladi" class="dataset">
          <h3><a href="/ladi/">Low Altitude Disaster Imagery (LADI) Dataset</a></h3>
          <p><span class="label label-info tag link-tag">aerial imagery</span><span class="label label-info tag link-tag">coastal</span><span class="label label-info tag link-tag">computer vision</span><span class="label label-info tag link-tag">disaster response</span><span class="label label-info tag link-tag">earth observation</span><span class="label label-info tag link-tag">earthquakes</span><span class="label label-info tag link-tag">geospatial</span><span class="label label-info tag link-tag">image processing</span><span class="label label-info tag link-tag">imaging</span><span class="label label-info tag link-tag">infrastructure</span><span class="label label-info tag link-tag">land</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">mapping</span><span class="label label-info tag link-tag">natural resource</span><span class="label label-info tag link-tag">seismology</span><span class="label label-info tag link-tag">transportation</span><span class="label label-info tag link-tag">urban</span><span class="label label-info tag link-tag">water</span></p>
          <p>The Low Altitude Disaster Imagery (LADI) Dataset consists of human and machine annotated airborne images collected by the Civil Air Patrol in support of various disaster responses from 2015-2019. The initial release of LADI focuses on the Atlantic hurricane seasons and coastal states along the Atlantic Ocean and Gulf of Mexico. Annotations are included for major hurricanes of Harvey, Maria, and Florence. Two key distinctions are the low altitude, oblique perspective of the imagery and disaster-related features, which are rarely featured in computer vision benchmarks and datasets.</p>
          <p><a href="/ladi/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://github.com/LADI-Dataset/ladi-tutorial" class="" target="_none">LADI Tutorials</a> by <a href="https://github.com/LADI-Dataset" target="_none">Andrew Weinert, Jianyu Mao, Kiana Harris, Nae-Rong Chang, Caleb Pennell, Yiming Ren, Ryan Earley, Nadia Dimitrova</a></li></a>
          </li>
          <li>
            <a href="https://doi.org/10.1109/HPEC.2019.8916437" class="" target="_none">Large Scale Organization and Inference of an Imagery Dataset for Public Safety</a> by Jeffrey Liu, David Strohschein, Siddharth Samsi, Andrew Weinert</li></a>
          </li>
          <li>
            <a href="https://www-nlpir.nist.gov/projects/tv2020/dsdi.html" class="" target="_none">NIST TRECVID 2020 - Disaster Scene Description and Indexing (DSDI)</a> by TREC Video Retrieval Evaluation (TRECVID)</li></a>
          </li>
          <li>
            <a href="https://github.com/bwsi-hadr" class="" target="_none">Remote Sensing for Disaster Response Course</a> by <a href="https://beaverworks.ll.mit.edu/CMS/bw/bwsi" target="_none">Beaver Works Summer Institute</a></li></a>
          </li>
          <li>
            <a href="https://doi.org/10.1109/LNET.2019.2955833" class="" target="_none">Video Testing at the FirstNet Innovation and Test Lab Using a Public Safety Dataset</a> by Chris Budny, Jeffrey Liu, Andrew Weinert</li></a>
          </li>
        </ul>
        <p><a href="/ladi/#usageexamples">See 6 usage examples &rarr;</a></p>
        </div>
        <div id="nyc-tlc-trip-records-pds" class="dataset">
          <h3><a href="/nyc-tlc-trip-records-pds/">New York City Taxi and Limousine Commission (TLC) Trip Record Data</a></h3>
          <p><span class="label label-info tag link-tag">cities</span><span class="label label-info tag link-tag">transportation</span><span class="label label-info tag link-tag">urban</span></p>
          <p>Data of trips taken by taxis and for-hire vehicles in New York City.</p>
          <p><a href="/nyc-tlc-trip-records-pds/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://aws.amazon.com/blogs/big-data/build-a-real-time-stream-processing-pipeline-with-apache-flink-on-aws/" class="aws-link" target="_none">Build a Real-time Stream Processing Pipeline with Apache Flink on AWS</a> by Steffen Hausmann</li></a>
          </li>
          <li>
            <a href="https://www.youtube.com/watch?v&#x3D;MzTZp47Jy7E" class="" target="_none">Deep Dive on Flink &amp; Spark on Amazon EMR</a> by Keith Steward</li></a>
          </li>
          <li>
            <a href="https://github.com/aws-samples/aws-open-data-analytics-notebooks/tree/master/optimizing-data" class="aws-link" target="_none">Optimizing data for analysis with Amazon Athena and AWS Glue</a> by Manav Sehgal</li></a>
          </li>
          <li>
            <a href="https://aws.amazon.com/blogs/big-data/build-and-run-streaming-applications-with-apache-flink-and-amazon-kinesis-data-analytics-for-java-applications/" class="aws-link" target="_none">Build and run streaming applications with Apache Flink and Amazon Kinesis Data Analytics for Java Applications</a> by Steffen Hausmann</li></a>
          </li>
          <li>
            <a href="https://github.com/aws-samples/aws-open-data-analytics-notebooks/tree/master/exploring-data" class="aws-link" target="_none">Exploring data with Python and Amazon S3 Select</a> by Manav Sehgal</li></a>
          </li>
        </ul>
        <p><a href="/nyc-tlc-trip-records-pds/#usageexamples">See 5 usage examples &rarr;</a></p>
        </div>
        <div id="pmsp-lidar" class="dataset">
          <h3><a href="/pmsp-lidar/">Prefeitura Municipal de São Paulo (PMSP) LiDAR Point Cloud</a></h3>
          <p><span class="label label-info tag link-tag">cities</span><span class="label label-info tag link-tag">elevation</span><span class="label label-info tag link-tag">geospatial</span><span class="label label-info tag link-tag">land</span><span class="label label-info tag link-tag">lidar</span><span class="label label-info tag link-tag">mapping</span><span class="label label-info tag link-tag">urban</span></p>
          <p>The objective of the Mapa 3D Digital da Cidade (M3DC) of the São Paulo City Hall is to publish LiDAR point cloud data. The initial data was acquired in 2017 by aerial surveying and future data will be added. This publicly accessible dataset is provided in the <a href="https://entwine.io/entwine-point-tile.html">Entwine Point Tiles</a> format as a lossless octree, full density, based on <a href="https://laszip.org">LASzip</a> (LAZ) encoding.</p>
          <p><a href="/pmsp-lidar/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="http://forsys.sefs.uw.edu/fusion/fusionlatest.html" class="" target="_none">Fusion</a> by <a href="https://www.usda.gov/" target="_none">US Department of Agriculture - Forest Service</a></li></a>
          </li>
          <li>
            <a href="https://doi.org/10.5194/isprs-annals-IV-2-W5-437-2019" class="" target="_none">Describing the Vertical Structure of Informal Settlements on the Basis of LiDAR Data – A Case Study for Favelas (Slums) in Sao Paulo City</a> by S. C. L. Ribeiro, M. Jarzabek-Rychard, J. P. Cintra, H.-G. Maas</li></a>
          </li>
          <li>
            <a href="https://entwine.io/" class="" target="_none">Entwine</a> by <a href="https://hobu.co/" target="_none">Hobu, Inc.</a></li></a>
          </li>
          <li>
            <a href="https://rapidlasso.com/lastools/" class="" target="_none">LAStools</a> by <a href="https://rapidlasso.com" target="_none">rapidlasso GmbH, GERMANY</a></li></a>
          </li>
          <li>
            <a href="https://pdal.io/" class="" target="_none">PDAL - Point Data Abstraction Library</a> by <a href="https://doi.org/10.5281/zenodo.2556738" target="_none">PDAL Contributors</a></li></a>
          </li>
        </ul>
        <p><a href="/pmsp-lidar/#usageexamples">See 5 usage examples &rarr;</a></p>
        </div>
        <div id="ford-multi-av-seasonal" class="dataset">
          <h3><a href="/ford-multi-av-seasonal/">Ford Multi-AV Seasonal Dataset</a></h3>
          <p><span class="label label-info tag link-tag">autonomous vehicles</span><span class="label label-info tag link-tag">computer vision</span><span class="label label-info tag link-tag">lidar</span><span class="label label-info tag link-tag">mapping</span><span class="label label-info tag link-tag">robotics</span><span class="label label-info tag link-tag">transportation</span><span class="label label-info tag link-tag">urban</span><span class="label label-info tag link-tag">weather</span></p>
          <p>This research presents a challenging multi-agent seasonal dataset collected by a fleet of Ford autonomous vehicles at different days and times during 2017-18. The vehicles The vehicles were manually driven on an average route of 66 km in Michigan that included a mix of driving scenarios like the Detroit Airport, freeways, city-centres, university campus and suburban neighbourhood, etc. Each vehicle used in this data collection  is a Ford Fusion outfitted with an Applanix POS-LV inertial measurement unit (IMU), four HDL-32E Velodyne 3D-lidar scanners, 6 Point Grey 1.3 MP Cameras arranged on the...</p>
          <p><a href="/ford-multi-av-seasonal/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://github.com/Ford/AVData" class="" target="_none">Ford AV Dataset Tutorial</a> by Ford Motor Company</li></a>
          </li>
        </ul>
        <p><a href="/ford-multi-av-seasonal/#usageexamples">See 1 usage example &rarr;</a></p>
        </div>
        <div id="spatial-ucr" class="dataset">
          <h3><a href="/spatial-ucr/">Geosnap Data, Center for Geospatial Sciences</a></h3>
          <p><span class="label label-info tag link-tag">demographics</span><span class="label label-info tag link-tag">geospatial</span><span class="label label-info tag link-tag">urban</span></p>
          <p>This bucket contains multiple datasets (as Quilt packages) created by the
Center for Geospatial Sciences (CGS) at the University of California-Riverside.
The data in this bucket contains the following:1) Tabular and geographic data from the US Census
2) Land Cover imagery collected from <a href="https://www.mrlc.gov/">Multi-Resolution Land Characteristics Consortium</a>
3) Road network data processed from OpenStreetMap</p>
          <p><a href="/spatial-ucr/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://spatialucr.github.io/geosnap-guide/home" class="" target="_none">Geosnap User Guide</a> by <a href="https://knaaptime.com" target="_none">Eli Knaap</a></li></a>
          </li>
        </ul>
        <p><a href="/spatial-ucr/#usageexamples">See 1 usage example &rarr;</a></p>
        </div>
        <div id="mevadata" class="dataset">
          <h3><a href="/mevadata/">Multiview Extended Video with Activities (MEVA)</a></h3>
          <p><span class="label label-info tag link-tag">computer vision</span><span class="label label-info tag link-tag">urban</span><span class="label label-info tag link-tag">us</span></p>
          <p>The Multiview Extended Video with Activities (MEVA) dataset consists
video data of human activity, both scripted and unscripted,
collected with roughly 100 actors over several weeks.  The data was
collected with 29 cameras with overlapping and non-overlapping
fields of view. The current release consists of about 328 hours
(516GB, 4259 clips) of video data, as well as 4.6 hours (26GB) of
UAV data. Other data includes GPS tracks of actors, camera models,
and a site map. We have also released annotations for 22 hours of
data. Further updates are planned.</p>
          <p><a href="/mevadata/">Details &rarr;</a></p>
        </div>
      </div>
    </div>


    <hr/>
  </div>  </body>
  <script src="/js/index.js"></script>
</html>
