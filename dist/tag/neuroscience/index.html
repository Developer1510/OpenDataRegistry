<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
  
    
  
    <link rel="alternate" type="application/rss+xml" href="/rss.xml" />
    
    <link rel="shortcut icon" type="image/ico" href="https://a0.awsstatic.com/libra-css/images/site/fav/favicon.ico"/>
    <link rel="apple-touch-icon" sizes="57x57" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-iphone-114-smile.png"/>
    <link rel="apple-touch-icon" sizes="72x72" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-ipad-144-smile.png"/>
    <link rel="apple-touch-icon" sizes="114x114" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-iphone-114-smile.png"/>
    <link rel="apple-touch-icon" sizes="144x144" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-ipad-144-smile.png"/>  
  
    <title>Registry of Open Data on AWS</title>
  
    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://assets.opendata.aws/css/bootstrap/3.4.1/bootstrap.min.css">
  
    <!-- Our local CSS -->
    <link rel="stylesheet" href="/css/main.css">
  
  
  </head>
  <body>
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://assets.opendata.aws/js/jquery/3.5.1/jquery.min.js"></script>
    <!-- Latest compiled and minified JavaScript -->
    <script src="https://assets.opendata.aws/js/bootstrap/3.4.1/bootstrap.min.js"></script>
    <nav class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <div class="roda-header">
          <h2><a href="/" alt="Home">Registry of Open Data on AWS</a></h2>
          <a href="http://aws.amazon.com/what-is-cloud-computing">
            <img src="https://assets.opendata.aws/img/AWS-Logo_White-Color_300x180.png" alt="Powered by AWS Cloud Computing" id="aws_header_logo">
          </a>
        </div>
      </div>
    </nav>
    <div class="container" >

    <div class="about col-md-5">
      <div class="row aboutbox">
            <h3>About</h3>
            <p>This registry exists to help people discover and share datasets that are available via AWS resources. <a href="https://opendata.aws">Learn more about sharing data on AWS</a>.</p>
    
            <p>See <a href="/tag/neuroscience/usage-examples">all usage examples for datasets listed in this registry</a> tagged with <strong>neuroscience</strong>.</p>
    
        <hr>
    
        <h4>Search datasets (currently <span id="count-matching">13</span> matching <span id="count-matching-text">datasets</span>)</h4>
        <form>
          <div class="form-group">
            <input type="text" id="search-box" class="form-control" placeholder="Search datasets" spellcheck="false" autocorrect="off">
          </div>
        </form>
        <p>You are currently viewing a subset of data tagged with <strong>neuroscience</strong>.</p>
    
        <hr>
    
        <h4>Add to this registry</h4>
        <p>If you want to add a dataset or example of how to use a dataset to this registry, please follow the instructions on the <a href="https://github.com/awslabs/open-data-registry/">Registry of Open Data on AWS GitHub repository</a>.</p>
    
        <p>Unless specifically stated in the applicable dataset documentation, datasets available through the Registry of Open Data on AWS are not provided and maintained by AWS. Datasets are provided and maintained by a variety of third parties under a variety of licenses. Please check dataset licenses and related documentation to determine if a dataset may be used for your application.</p>
      </div>
    </div>
    <div class="col-md-6 col-md-offset-1 datasets">
      <div class="row">
        <div id="fcp-indi" class="dataset">
          <h3><a href="/fcp-indi/">International Neuroimaging Data-Sharing Initiative (INDI)</a></h3>
          <p><span class="label label-info tag link-tag">Homo sapiens</span><span class="label label-info tag link-tag">life sciences</span><span class="label label-info tag link-tag">magnetic resonance imaging</span><span class="label label-info tag link-tag">neuroimaging</span><span class="label label-info tag link-tag">neuroscience</span></p>
          <p>This bucket contains multiple neuroimaging datasets that are part of the International Neuroimaging Data-Sharing Initiative. Raw human and non-human primate neuroimaging data include 1) Structural MRI; 2) Functional MRI; 3) Diffusion Tensor Imaging; 4) Electroencephalogram (EEG)
In addition to the raw data, preprocessed data is also included for some datasets.
A complete list of the available datasets can be seen in the documentation lonk provided below. </p>
          <p><a href="/fcp-indi/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://fcon_1000.projects.nitrc.org/indi/s3/index.html" class="" target="_none">Downloading FCP-INDI Neuroimaging Data from Amazon S3</a> by INDI</li></a>
          </li>
          <li>
            <a href="https://www.nature.com/articles/s41467-018-04976-1" class="" target="_none">Assessment of the impact of shared brain imaging data on the scientific literature</a> by M.P. Milham, R.C. Craddock, ..., A. Klein</li></a>
          </li>
          <li>
            <a href="https://www.nature.com/articles/sdata201710" class="" target="_none">Enhancing studies of the connectome in autism using the autism brain imaging data exchange II.</a> by A. Di Martino, D. O&#x27;Connor, M.P. Milham</li></a>
          </li>
          <li>
            <a href="https://www.sciencedirect.com/science/article/abs/pii/S1053811912010671?via%3Dihub" class="" target="_none">Making data sharing work: The FCP/INDI experience</a> by M. Mennes, B.B. Biswal, F.X. Castellanos, M.P. Milham</li></a>
          </li>
          <li>
            <a href="https://www.sciencedirect.com/science/article/pii/S0896627318307682" class="" target="_none">An Open Resource for Non-human Primate Imaging</a> by M.P. Milham, L. Ai, ..., C.E. Schroeder</li></a>
          </li>
        </ul>
        <p><a href="/fcp-indi/#usageexamples">See 11 usage examples &rarr;</a></p>
        </div>
        <div id="janelia-flylight" class="dataset">
          <h3><a href="/janelia-flylight/">Fly Brain Anatomy: FlyLight Gen1 and Split-GAL4 Imagery</a></h3>
          <p><span class="label label-info tag link-tag">biology</span><span class="label label-info tag link-tag">fluorescence imaging</span><span class="label label-info tag link-tag">image processing</span><span class="label label-info tag link-tag">life sciences</span><span class="label label-info tag link-tag">microscopy</span><span class="label label-info tag link-tag">neurobiology</span><span class="label label-info tag link-tag">neuroimaging</span><span class="label label-info tag link-tag">neuroscience</span></p>
          <p>This data set, made available by Janelia&#39;s FlyLight project, consists of fluorescence images 
of Drosophila melanogaster driver lines, aligned to standard templates, and stored in formats 
suitable for rapid searching and visualization. Additional data will be added as it is published. 
A large release of Gen1 MCFO samples is coming at the beginning of May 2020. </p>
          <p><a href="/janelia-flylight/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://neuronbridge.janelia.org" class="" target="_none">NeuronBridge</a> by Jody Clements, Rob Svirskas, Hideo Otsuna, Cristian Goina, Konrad Rokicki</li></a>
          </li>
          <li>
            <a href="https://doi.org/10.1101/318006" class="" target="_none">Color depth MIP mask search: a new tool to expedite Split-GAL4 creation</a> by Otsuna, H., Ito, M., &amp; Kawase, T.</li></a>
          </li>
          <li>
            <a href="https://doi.org/10.1016/j.celrep.2012.09.011" class="" target="_none">A GAL4-Driver Line Resource for Drosophila Neurobiology</a> by Jenett, A., Rubin, G. M., Ngo, T., Shepherd, D., Murphy, C., Dionne, H., Pfeiffer, B. D., Cavallaro, A., Hall, D., Jeter, J., Iyer, N., Fetter, D., Hausenfluck, J. H., Peng, H., Trautman, E. T., Svirskas, R. R., Myers, E. W., Iwinski, Z. R., Aso, Y., DePasquale, G. M., Enos, A., Hulamm, P., Lam, S. C. B., Li, H., Laverty, T. R., Long, F., Qu, L., Murphy, S. D., Rokicki, K., Safford, T., Shaw, K., Simpson, J. H., Sowell, A., Tae, S., Yu, Y., &amp; Zugates, C. T.</li></a>
          </li>
          <li>
            <a href="https://github.com/JaneliaSciComp/open-data-flylight/blob/master/tutorials/File_operations_on_AWS_S3.ipynb" class="" target="_none">File Operations on AWS S3</a> by Rob Svirskas</li></a>
          </li>
          <li>
            <a href="http://splitgal4.janelia.org/cgi-bin/splitgal4.cgi" class="" target="_none">Fly Light Split-GAL4 Driver Collection</a> by Rob Svirskas</li></a>
          </li>
        </ul>
        <p><a href="/janelia-flylight/#usageexamples">See 10 usage examples &rarr;</a></p>
        </div>
        <div id="open-neurodata" class="dataset">
          <h3><a href="/open-neurodata/">Open NeuroData</a></h3>
          <p><span class="label label-info tag link-tag">array tomography</span><span class="label label-info tag link-tag">biology</span><span class="label label-info tag link-tag">electron microscopy</span><span class="label label-info tag link-tag">image processing</span><span class="label label-info tag link-tag">life sciences</span><span class="label label-info tag link-tag">lightsheet microscopy</span><span class="label label-info tag link-tag">magnetic resonance imaging</span><span class="label label-info tag link-tag">neuroimaging</span><span class="label label-info tag link-tag">neuroscience</span></p>
          <p>This bucket contains multiple neuroimaging datasets (as Neuroglancer Precomputed Volumes) across multiple modalities and scales, ranging from nanoscale (electron microscopy), to microscale (cleared lightsheet microscopy and array tomography), and mesoscale (structural and functional magnetic resonance imaging). Additionally, many of the datasets include segmentations and meshes.</p>
          <p><a href="/open-neurodata/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://neurodata.io/help/visualization/" class="" target="_none">Visualization using Neuroglancer</a> by <a href="https://github.com/falkben" target="_none">Benjamin Falk</a></li></a>
          </li>
          <li>
            <a href="https://arxiv.org/abs/1306.3543" class="" target="_none">The Open Connectome Project Data Cluster: Scalable Analysis and Vision for High-Throughput Neuroscience</a> by R. Burns, W. G. Roncal, D. Kleissas, K. Lillaney, P. Manavalan, E. Perlman, D. R. Berger, D. D. Bock, K. Chung, L. Grosenick, N. Kasthuri, N. C. Weiler, K. Deisseroth, M. Kazhdan, J. Lichtman, R. C. Reid, S. J. Smith, A. S. Szalay, J. T. Vogelstein, and R. J. Vogelstein.</li></a>
          </li>
          <li>
            <a href="https://doi.org/10.1016/j.neuron.2016.10.033" class="" target="_none">To the Cloud! A Grassroots Proposal to Accelerate Brain Science Discovery</a> by J. T. Vogelstein, B. Mensh, M. Häusser, N. Spruston, A. C. Evans, K. Kording, K. Amunts, C. Ebell, J. Muller, M. Telefont, S. Hill, S. P. Koushika, C. Calì, P. A. Valdés-Sosa, P. B. Littlewood, C. Koch, S. Saalfeld, A. Kepecs, H. Peng, Y. O. Halchenko, G. Kiar, M. M. Poo, J. B. Poline, M. P. Milham, A. P. Schaffer, R. Gidron, H. Okano, V. D. Calhoun, M. Chun, D. M. Kleissas, R. J. Vogelstein, E. Perlman, R. Burns, R. Huganir, and M. I. Miller</li></a>
          </li>
          <li>
            <a href="https://doi.org/10.1016/j.neuron.2014.08.045" class="" target="_none">From cosmos to connectomes: The evolution of data-intensive science</a> by R. Burns, J. T. Vogelstein, and A. S. Szalay</li></a>
          </li>
          <li>
            <a href="https://www.nature.com/articles/s41592-018-0181-1" class="" target="_none">A Community-Developed Open-Source Computational Ecosystem for Big Neuro Data</a> by J. T. Vogelstein, E. Perlman, B. Falk, A. Baden, W. Gray Roncal, V. Chandrashekhar, F. Collman, S. Seshamani, J. L. Patsolic, K. Lillaney, M. Kazhdan, R. Hider, D. Pryor, J. Matelsky, T. Gion, P. Manavalan, B. Wester, M. Chevillet, E. T. Trautman, K. Khairy, E. Bridgeford, D. M. Kleissas, D. J. Tward, A. K. Crow, B. Hsueh, M. A. Wright, M. I. Miller, S. J. Smith, R. J. Vogelstein, K. Deisseroth, and R. Burns</li></a>
          </li>
        </ul>
        <p><a href="/open-neurodata/#usageexamples">See 9 usage examples &rarr;</a></p>
        </div>
        <div id="dandiarchive" class="dataset">
          <h3><a href="/dandiarchive/">Distributed Archives for Neurophysiology Data Integration (DANDI)</a></h3>
          <p><span class="label label-info tag link-tag">biology</span><span class="label label-info tag link-tag">cell imaging</span><span class="label label-info tag link-tag">electrophysiology</span><span class="label label-info tag link-tag">infrastructure</span><span class="label label-info tag link-tag">life sciences</span><span class="label label-info tag link-tag">neuroimaging</span><span class="label label-info tag link-tag">neurophysiology</span><span class="label label-info tag link-tag">neuroscience</span></p>
          <p>DANDI is a public archive of neurophysiology datasets, including raw and processed data,  and associated software containers. Datasets are shared according to a Creative Commons  CC0 or CC-BY licenses. The data archive provides a broad range of cellular neurophysiology data.  This includes electrode and optical recordings, and associated imaging data using a  set of community standards: <a href="https://www.nwb.org/nwb-neurophysiology/">NWB:N - NWB:Neurophysiology</a>, <a href="https://bids.neuroimaging.io/">BIDS - Brain Imaging Data Structure</a>, and  <a href="htt...</p>
          <p><a href="/dandiarchive/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://dandiarchive.org/" class="" target="_none">DANDI Web Interface</a> by <a href="https://dandiarchive.org/" target="_none">DANDI Project</a></li></a>
          </li>
          <li>
            <a href="https://github.com/dandi/dandi-cli" class="" target="_none">DANDI Shell Interface</a> by <a href="https://dandiarchive.org/" target="_none">DANDI Project</a></li></a>
          </li>
          <li>
            <a href="https://hub.dandiarchive.org/" class="" target="_none">DANDI JupyterHub Interface</a> by <a href="https://dandiarchive.org/" target="_none">DANDI Project</a></li></a>
          </li>
        </ul>
        <p><a href="/dandiarchive/#usageexamples">See 3 usage examples &rarr;</a></p>
        </div>
        <div id="nsd" class="dataset">
          <h3><a href="/nsd/">Natural Scenes Dataset</a></h3>
          <p><span class="label label-info tag link-tag">computer vision</span><span class="label label-info tag link-tag">image processing</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">magnetic resonance imaging</span><span class="label label-info tag link-tag">neuroimaging</span><span class="label label-info tag link-tag">neuroscience</span><span class="label label-info tag link-tag">nifti</span></p>
          <p>Here, we collected and pre-processed a massive, high-quality 7T fMRI dataset that can be used to advance our understanding of how the brain works. A unique feature of this dataset is the massive amount of data available per individual subject. The data were acquired using ultra-high-field fMRI (7T, whole-brain, 1.8-mm resolution, 1.6-s TR). We measured fMRI responses while each of 8 participants viewed 9,000–10,000 distinct, color natural scenes (22,500–30,000 trials) in 30–40 weekly scan sessions over the course of a year. Additional measures were collected including resting-state data, retin...</p>
          <p><a href="/nsd/">Details &rarr;</a></p>
        </div>
      </div>
    </div>


    <hr/>
  </div>  </body>
  <script src="/js/index.js"></script>
</html>
