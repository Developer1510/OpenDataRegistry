<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
  
    
  
    <link rel="alternate" type="application/rss+xml" href="/rss.xml" />
    
    <link rel="shortcut icon" type="image/ico" href="https://a0.awsstatic.com/libra-css/images/site/fav/favicon.ico"/>
    <link rel="apple-touch-icon" sizes="57x57" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-iphone-114-smile.png"/>
    <link rel="apple-touch-icon" sizes="72x72" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-ipad-144-smile.png"/>
    <link rel="apple-touch-icon" sizes="114x114" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-iphone-114-smile.png"/>
    <link rel="apple-touch-icon" sizes="144x144" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-ipad-144-smile.png"/>  
  
    <title>Registry of Open Data on AWS</title>
  
    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://assets.opendata.aws/css/bootstrap/3.4.1/bootstrap.min.css">
  
    <!-- Our local CSS -->
    <link rel="stylesheet" href="/css/main.css">
  
  
  </head>
  <body>
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://assets.opendata.aws/js/jquery/3.5.1/jquery.min.js"></script>
    <!-- Latest compiled and minified JavaScript -->
    <script src="https://assets.opendata.aws/js/bootstrap/3.4.1/bootstrap.min.js"></script>
    <nav class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <div class="roda-header">
          <h2><a href="/" alt="Home">Registry of Open Data on AWS</a></h2>
          <a href="http://aws.amazon.com/what-is-cloud-computing">
            <img src="https://assets.opendata.aws/img/AWS-Logo_White-Color_300x180.png" alt="Powered by AWS Cloud Computing" id="aws_header_logo">
          </a>
        </div>
      </div>
    </nav>
    <div class="container" >

    <div class="about col-md-5">
      <div class="row aboutbox">
            <h3>About</h3>
            <p>This registry exists to help people discover and share datasets that are available via AWS resources. <a href="https://opendata.aws">Learn more about sharing data on AWS</a>.</p>
    
            <p>See <a href="/tag/natural-language-processing/usage-examples">all usage examples for datasets listed in this registry</a> tagged with <strong>natural language processing</strong>.</p>
    
        <hr>
    
        <h4>Search datasets (currently <span id="count-matching">13</span> matching <span id="count-matching-text">datasets</span>)</h4>
        <form>
          <div class="form-group">
            <input type="text" id="search-box" class="form-control" placeholder="Search datasets" spellcheck="false" autocorrect="off">
          </div>
        </form>
        <p>You are currently viewing a subset of data tagged with <strong>natural language processing</strong>.</p>
    
        <hr>
    
        <h4>Add to this registry</h4>
        <p>If you want to add a dataset or example of how to use a dataset to this registry, please follow the instructions on the <a href="https://github.com/awslabs/open-data-registry/">Registry of Open Data on AWS GitHub repository</a>.</p>
    
        <p>Unless specifically stated in the applicable dataset documentation, datasets available through the Registry of Open Data on AWS are not provided and maintained by AWS. Datasets are provided and maintained by a variety of third parties under a variety of licenses. Please check dataset licenses and related documentation to determine if a dataset may be used for your application.</p>
      </div>
    </div>
    <div class="col-md-6 col-md-offset-1 datasets">
      <div class="row">
        <div id="commoncrawl" class="dataset">
          <h3><a href="/commoncrawl/">Common Crawl</a></h3>
          <p><span class="label label-info tag link-tag">encyclopedic</span><span class="label label-info tag link-tag">internet</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">natural language processing</span></p>
          <p>A corpus of web crawl data composed of over 50 billion web pages.</p>
          <p><a href="/commoncrawl/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="http://www.lrec-conf.org/proceedings/lrec2016/pdf/388_Paper.pdf" class="" target="_none">C4Corpus: Multilingual Web-Size Corpus with Free License</a> by <a href="https://dkpro.github.io/dkpro-c4corpus/" target="_none">Ivan Habernal, Omnia Zayed, Iryna Gurevych</a></li></a>
          </li>
          <li>
            <a href="https://www.aclweb.org/anthology/L18-1550" class="" target="_none">Learning word vectors for 157 languages</a> by <a href="https://fasttext.cc/docs/en/crawl-vectors.html" target="_none">Facebook AI Research</a></li></a>
          </li>
          <li>
            <a href="https://commoncrawl.org/2018/03/index-to-warc-files-and-urls-in-columnar-format/" class="" target="_none">Index to WARC Files and URLs in Columnar Format</a> by Sebastian Nagel</li></a>
          </li>
          <li>
            <a href="https://wwwdb.inf.tu-dresden.de/research-projects/dresden-web-table-corpus/" class="" target="_none">Dresden Web Table Corpus (DWTC)</a> by <a href="https://wwwdb.inf.tu-dresden.de/" target="_none">Database Systems Group Dresden</a></li></a>
          </li>
          <li>
            <a href="https://doi.org/10.1007/s10579-020-09489-2" class="" target="_none">Mapping languages: The Corpus of Global Language Use</a> by <a href="https://www.earthlings.io/" target="_none">Jonathan Dunn</a></li></a>
          </li>
        </ul>
        <p><a href="/commoncrawl/#usageexamples">See 23 usage examples &rarr;</a></p>
        </div>
        <div id="sudachi" class="dataset">
          <h3><a href="/sudachi/">Sudachi Language Resources</a></h3>
          <p><span class="label label-info tag link-tag">natural language processing</span></p>
          <p>Japanese dictionaries and word embeddings for natural language processing.
<a href="https://github.com/WorksApplications/SudachiDict">SudachiDict</a> is the dictionary for a Japanese tokenizer (morphological analyzer) <a href="https://github.com/WorksApplications/Sudachi">Sudachi</a>.
<a href="https://github.com/WorksApplications/chiVe">chiVe</a> is Japanese pretrained word embeddings (word vectors), trained using the ultra-large-scale web corpus NWJC by National Institute for Japanese Langauge and Linguistics, analyzed by Sudachi.</p>
          <p><a href="/sudachi/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://github.com/WorksApplications/SudachiPy/blob/develop/docs/tutorial.md" class="" target="_none">SudachiPy Tutorial</a> by Works Applications</li></a>
          </li>
          <li>
            <a href="https://pypi.org/project/SudachiDict-full/" class="" target="_none">sudachidict_full on pypi.python.org - a Python module to download and install SudachiDict for the python tokenizer</a> by Works Applications</li></a>
          </li>
          <li>
            <a href="https://www.ieice.org/ken/paper/20200910U1zQ/" class="" target="_none">chiVe: 製品利用可能な日本語単語ベクトル資源の実現へ向けて ～形態素解析器Sudachiと超大規模ウェブコーパスNWJCによる分散表現の獲得と改良～</a> by 久本空海, 山村崇, 勝田哲弘, 竹林佑斗, 髙岡一馬, 内田佳孝, 岡照晃, 浅原正幸</li></a>
          </li>
          <li>
            <a href="https://pypi.org/project/SudachiDict-core/" class="" target="_none">sudachidict_core on pypi.python.org - a Python module to download and install SudachiDict for the python tokenizer</a> by Works Applications</li></a>
          </li>
          <li>
            <a href="http://www.lrec-conf.org/proceedings/lrec2018/summaries/8884.html" class="" target="_none">Sudachi: a Japanese Tokenizer for Business</a> by Kazuma Takaoka, Sorami Hisamoto, Noriko Kawahara, Miho Sakamoto, Yoshitaka Uchida, Yuji Matsumoto</li></a>
          </li>
        </ul>
        <p><a href="/sudachi/#usageexamples">See 18 usage examples &rarr;</a></p>
        </div>
        <div id="cotonoha-dic" class="dataset">
          <h3><a href="/cotonoha-dic/">Japanese Tokenizer Dictionaries</a></h3>
          <p><span class="label label-info tag link-tag">csv</span><span class="label label-info tag link-tag">japanese</span><span class="label label-info tag link-tag">natural language processing</span></p>
          <p>Japanese Tokenizer Dictionaries for use with MeCab.</p>
          <p><a href="/cotonoha-dic/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://www.dampfkraft.com/nlp/how-to-tokenize-japanese.html" class="" target="_none">How to Tokenize Japanese in Python</a> by <a href="https://dampfkraft.com" target="_none">Paul O&#x27;Leary McCann</a></li></a>
          </li>
          <li>
            <a href="https://github.com/polm/unidic-py" class="" target="_none">unidic-py</a> by <a href="https://cotonoha.io" target="_none">Paul O&#x27;Leary McCann</a></li></a>
          </li>
          <li>
            <a href="https://github.com/polm/fugashi-sagemaker-demo/blob/master/fugashi%20wordcount.ipynb" class="" target="_none">Fugashi Word Count Tutorial</a> by <a href="https://cotonoha.io" target="_none">Paul O&#x27;Leary McCann</a></li></a>
          </li>
        </ul>
        <p><a href="/cotonoha-dic/#usageexamples">See 3 usage examples &rarr;</a></p>
        </div>
        <div id="mimiciii" class="dataset">
          <h3><a href="/mimiciii/">MIMIC-III (‘Medical Information Mart for Intensive Care’)</a></h3>
          <p><span class="label label-info tag link-tag">bioinformatics</span><span class="label label-info tag link-tag">health</span><span class="label label-info tag link-tag">life sciences</span><span class="label label-info tag link-tag">natural language processing</span><span class="label label-info tag link-tag">us</span></p>
          <p>MIMIC-III (‘Medical Information Mart for Intensive Care’) is a large, 
single-center database comprising information relating to patients 
admitted to critical care units at a large tertiary care hospital. 
Data includes vital signs, medications, laboratory measurements, 
observations and notes charted by care providers, fluid balance, 
procedure codes, diagnostic codes, imaging reports, hospital length 
of stay, survival data, and more. The database supports applications 
including academic and industrial research, quality improvement initiatives, 
and higher education coursework. The MIMIC-I...</p>
          <p><a href="/mimiciii/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://aws.amazon.com/blogs/big-data/perform-biomedical-informatics-without-a-database-using-mimic-iii-data-and-amazon-athena/" class="aws-link" target="_none">Perform biomedical informatics without a database using MIMIC-III data and Amazon Athena</a> by James Wiggins, Alistair Johnson</li></a>
          </li>
          <li>
            <a href="https://github.com/MIT-LCP/mimic-code" class="" target="_none">MIMIC-code GitHub repository</a> by <a href="https://github.com/alistairewj" target="_none">Alistair Johnson</a></li></a>
          </li>
        </ul>
        <p><a href="/mimiciii/#usageexamples">See 2 usage examples &rarr;</a></p>
        </div>
        <div id="answer-reformulation" class="dataset">
          <h3><a href="/answer-reformulation/">Answer Reformulation</a></h3>
          <p><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">natural language processing</span></p>
          <p>Original StackExchange answers and their voice-friendly Reformulation.</p>
          <p><a href="/answer-reformulation/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://www2020.thewebconf.org/" class="" target="_none">Voice-based Reformulation of Community Answers</a> by Simone Filice, Nachshon Cohen &amp; David Carmel</li></a>
          </li>
        </ul>
        <p><a href="/answer-reformulation/#usageexamples">See 1 usage example &rarr;</a></p>
        </div>
        <div id="asr-error-robustness" class="dataset">
          <h3><a href="/asr-error-robustness/">Automatic Speech Recognition (ASR) Error Robustness</a></h3>
          <p><span class="label label-info tag link-tag">deep learning</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">natural language processing</span><span class="label label-info tag link-tag">speech recognition</span></p>
          <p>Sentence classification datatasets with ASR Errors.</p>
          <p><a href="/asr-error-robustness/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://assets.amazon.science/64/94/639ae0c44890837b0f1fbf11ef77/using-phoneme-representations-to-build-predictive-models-robust-to-asr-errors.pdf" class="" target="_none">Using Phoneme Representations to Build Predictive Models Robust to ASR Errors</a> by <a href="https://anjiefang.github.io" target="_none">Anjie Fang, Simone Filice, Nut Limsopatham and Oleg Rokhlenko</a></li></a>
          </li>
        </ul>
        <p><a href="/asr-error-robustness/#usageexamples">See 1 usage example &rarr;</a></p>
        </div>
        <div id="dialoglue" class="dataset">
          <h3><a href="/dialoglue/">DialoGLUE: A Natural Language Understanding Benchmark for Task-Oriented Dialogue</a></h3>
          <p><span class="label label-info tag link-tag">conversation data</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">natural language processing</span></p>
          <p>This bucket contains the checkpoints used to reproduce the baseline results reported in the DialoGLUE benchmark hosted
on EvalAI (<a href="https://evalai.cloudcv.org/web/challenges/challenge-page/708/overview">https://evalai.cloudcv.org/web/challenges/challenge-page/708/overview</a>). The associated scripts for using the checkpoints are located here:
<a href="https://github.com/alexa/dialoglue">https://github.com/alexa/dialoglue</a>. The associated paper describing the benchmark and checkpoints is here: <a href="https://arxiv.org/abs/2009.13570">https://arxiv.org/abs/2009.13570</a>.
The provided checkpoints include the CONVBERT model, a BERT-esque model trained on a large open-domain conversational
dataset. It also includes the CONVBERT-DG and BERT-DG checkpoints descri...</p>
          <p><a href="/dialoglue/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://arxiv.org/abs/2009.13570" class="" target="_none">DialoGLUE: A Natural Language Understanding Benchmark for Task-Oriented Dialogue</a> by Shikib Mehri, Mihail Eric, Dilek Hakkani-Tur</li></a>
          </li>
        </ul>
        <p><a href="/dialoglue/#usageexamples">See 1 usage example &rarr;</a></p>
        </div>
        <div id="topical-chat-enriched" class="dataset">
          <h3><a href="/topical-chat-enriched/">Enriched Topical-Chat Dataset for Knowledge-Grounded Dialogue Systems</a></h3>
          <p><span class="label label-info tag link-tag">conversation data</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">natural language processing</span></p>
          <p>This dataset provides extra annotations on top of the publicly released
Topical-Chat dataset(<a href="https://github.com/alexa/Topical-Chat">https://github.com/alexa/Topical-Chat</a>) which will help in reproducing the results in our paper
&quot;Policy-Driven Neural Response Generation for Knowledge-Grounded Dialogue Systems&quot; (<a href="https://arxiv.org/abs/2005.12529?context=cs.CL">https://arxiv.org/abs/2005.12529?context=cs.CL</a>). 
The dataset contains 5 files: train.json, valid_freq.json, valid_rare.json, test_freq.json and test_rare.json. 
Each of these files will have additional annotations on top of the original Topical-Chat dataset.
These specific annotations are: dialogue act annotations a...</p>
          <p><a href="/topical-chat-enriched/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://arxiv.org/abs/2005.12529?context&#x3D;cs.CL" class="" target="_none">Policy-Driven Neural Response Generation for Knowledge-Grounded Dialogue Systems</a> by Behnam Hedayatnia, Karthik Gopalakrishnan, Seokhwan Kim, Yang Liu, Mihail Eric &amp; Dilek Hakkani-Tur</li></a>
          </li>
        </ul>
        <p><a href="/topical-chat-enriched/#usageexamples">See 1 usage example &rarr;</a></p>
        </div>
        <div id="humor-detection" class="dataset">
          <h3><a href="/humor-detection/">Humor Detection from Product Question Answering Systems</a></h3>
          <p><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">natural language processing</span></p>
          <p>This dataset provides labeled humor detection from product question answering systems.
The dataset contains 3 csv files: <a href="https://humor-detection-pds.s3-us-west-2.amazonaws.com/Humorous.csv">Humorous.csv</a> 
containing the humorous product questions, 
<a href="https://humor-detection-pds.s3-us-west-2.amazonaws.com/Non-humorous-unbiased.csv">Non-humorous-unbiased.csv</a> containing 
the non-humorous prodcut questions from the same products as the humorous one, and, 
<a href="https://humor-detection-pds.s3-us-west-2.a...</p>
          <p><a href="/humor-detection/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://sigir.org/sigir2020/" class="" target="_none">Humor Detection in Product Question Answering Systems.</a> by Yftah Ziser, Elad Kravi &amp; David Carmel</li></a>
          </li>
        </ul>
        <p><a href="/humor-detection/#usageexamples">See 1 usage example &rarr;</a></p>
        </div>
        <div id="amazon-reviews-ml" class="dataset">
          <h3><a href="/amazon-reviews-ml/">The Multilingual Amazon Reviews Corpus</a></h3>
          <p><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">natural language processing</span></p>
          <p>We present a collection of Amazon reviews specifically designed to aid research in multilingual text classification. The dataset contains reviews in English, Japanese, German, French, Chinese and Spanish, collected between November 1, 2015 and November 1, 2019. Each record in the dataset contains the review text, the review title, the star rating, an anonymized reviewer ID, an anonymized product ID and the coarse-grained product category (e.g. &#39;books&#39;, &#39;appliances&#39;, etc.)</p>
          <p><a href="/amazon-reviews-ml/">Details &rarr;</a></p>
          <h4>Usage examples</h4>
          <ul class="dataatwork-list">
          <li>
            <a href="https://arxiv.org/abs/2010.02573" class="" target="_none">The Multilingual Amazon Reviews Corpus</a> by Phillip Keung, Yichao Lu, György Szarvas, Noah A. Smith</li></a>
          </li>
        </ul>
        <p><a href="/amazon-reviews-ml/#usageexamples">See 1 usage example &rarr;</a></p>
        </div>
        <div id="google-ngrams" class="dataset">
          <h3><a href="/google-ngrams/">Google Books Ngrams</a></h3>
          <p><span class="label label-info tag link-tag">natural language processing</span></p>
          <p>N-grams are fixed size tuples of items. In this case the items are words extracted from the Google Books corpus. The n specifies the number of elements in the tuple, so a 5-gram contains five words or characters. The n-grams in this dataset were produced by passing a sliding window of the text of books and outputting a record for each new token.</p>
          <p><a href="/google-ngrams/">Details &rarr;</a></p>
        </div>
        <div id="fast-ai-nlp" class="dataset">
          <h3><a href="/fast-ai-nlp/">NLP - fast.ai datasets</a></h3>
          <p><span class="label label-info tag link-tag">deep learning</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">natural language processing</span></p>
          <p>Some of the most important datasets for NLP, with a focus on classification, including
IMDb, AG-News, Amazon Reviews (polarity and full), Yelp Reviews (polarity and
full), Dbpedia, Sogou News (Pinyin), Yahoo Answers, Wikitext 2 and Wikitext
103, and ACL-2010 French-English 10^9 corpus.  This is part of the
fast.ai datasets collection hosted by AWS for convenience of fast.ai
students. See documentation link for citation and license details for each
dataset.</p>
          <p><a href="/fast-ai-nlp/">Details &rarr;</a></p>
        </div>
        <div id="paracrawl" class="dataset">
          <h3><a href="/paracrawl/">Provision of Web-Scale Parallel Corpora for Official European Languages (ParaCrawl)</a></h3>
          <p><span class="label label-info tag link-tag">machine translation</span><span class="label label-info tag link-tag">natural language processing</span></p>
          <p>ParaCrawl is a set of large parallel corpora to/from English for all official EU languages by a broad web crawling effort. State-of-the-art methods are applied for the entire processing chain from identifying web sites with translated text all the way to collecting, cleaning and delivering parallel corpora that are ready as training data for CEF.AT and translation memories for DG Translation.</p>
          <p><a href="/paracrawl/">Details &rarr;</a></p>
        </div>
        <div id="mmid" class="dataset">
          <h3><a href="/mmid/">The Massively Multilingual Image Dataset (MMID)</a></h3>
          <p><span class="label label-info tag link-tag">computer vision</span><span class="label label-info tag link-tag">machine learning</span><span class="label label-info tag link-tag">machine translation</span><span class="label label-info tag link-tag">natural language processing</span></p>
          <p>MMID is a large-scale, massively multilingual dataset of images paired with the words they represent collected at the <a href="https://upenn.edu">University of Pennsylvania</a>.
The dataset is doubly parallel: for each language, words are stored parallel to images that represent the word, <em>and</em> parallel to the word&#39;s translation into English (and corresponding images.)</p>
          <p><a href="/mmid/">Details &rarr;</a></p>
        </div>
      </div>
    </div>


    <hr/>
  </div>  </body>
  <script src="/js/index.js"></script>
</html>
