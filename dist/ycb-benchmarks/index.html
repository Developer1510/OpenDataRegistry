<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
  
    
  
    <link rel="alternate" type="application/rss+xml" href="/rss.xml" />
    
    <link rel="shortcut icon" type="image/ico" href="https://a0.awsstatic.com/libra-css/images/site/fav/favicon.ico"/>
    <link rel="apple-touch-icon" sizes="57x57" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-iphone-114-smile.png"/>
    <link rel="apple-touch-icon" sizes="72x72" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-ipad-144-smile.png"/>
    <link rel="apple-touch-icon" sizes="114x114" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-iphone-114-smile.png"/>
    <link rel="apple-touch-icon" sizes="144x144" href="https://a0.awsstatic.com/libra-css/images/site/touch-icon-ipad-144-smile.png"/>  
  
    <title>Yale-CMU-Berkeley (YCB) Object and Model Set - Registry of Open Data on AWS</title>
  
    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://assets.opendata.aws/css/bootstrap/3.4.1/bootstrap.min.css">
  
    <!-- Our local CSS -->
    <link rel="stylesheet" href="/css/main.css">
  
    <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Dataset",
      "name" : "Yale-CMU-Berkeley (YCB) Object and Model Set",
      "description" : "This project primarily aims to facilitate performance benchmarking in robotics research. The dataset provides mesh models, RGB, RGB-D and point cloud images of over 80 objects. The physical objects are also available via the <a href=\"http://www.ycbbenchmarks.com/\">YCB benchmarking project</a>. The data are collected by two state of the art systems: UC Berkley&#39;s scanning rig and the Google scanner. The UC Berkley&#39;s scanning rig data provide meshes generated with Poisson reconstruction, meshes generated with volumetric range image integration, textured versions of both meshes, Kinbody files for using the meshes with OpenRAVE, 600 High-resolution RGB images, 600 RGB-D images, and 600 point cloud images for each object. The Google scanner data provides 3 meshes with different resolutions (16k, 64k, and 512k polygons), textured versions of each mesh, Kinbody files for using the meshes with OpenRAVE.",
      "license" : "Creative Commons Attribution 4.0 International (CC BY 4.0)"
    }
    </script>
  
  </head>
  <body>
    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://assets.opendata.aws/js/jquery/3.5.1/jquery.min.js"></script>
    <!-- Latest compiled and minified JavaScript -->
    <script src="https://assets.opendata.aws/js/bootstrap/3.4.1/bootstrap.min.js"></script>
    <nav class="navbar navbar-default navbar-fixed-top">
      <div class="container">
        <div class="roda-header">
          <h2><a href="/" alt="Home">Registry of Open Data on AWS</a></h2>
          <a href="http://aws.amazon.com/what-is-cloud-computing">
            <img src="https://assets.opendata.aws/img/AWS-Logo_White-Color_300x180.png" alt="Powered by AWS Cloud Computing" id="aws_header_logo">
          </a>
        </div>
      </div>
    </nav>
    <div class="container" >

    <h1>Yale-CMU-Berkeley (YCB) Object and Model Set</h1>
    <p>
      

      <span class="label label-info tag link-tag">robotics</span>
    </p>
    <div class="row">
      <div class="col-md-6">
      <h3>Description</h3>
      <p>This project primarily aims to facilitate performance benchmarking in robotics research. The dataset provides mesh models, RGB, RGB-D and point cloud images of over 80 objects. The physical objects are also available via the <a href="http://www.ycbbenchmarks.com/">YCB benchmarking project</a>. The data are collected by two state of the art systems: UC Berkley&#39;s scanning rig and the Google scanner. The UC Berkley&#39;s scanning rig data provide meshes generated with Poisson reconstruction, meshes generated with volumetric range image integration, textured versions of both meshes, Kinbody files for using the meshes with OpenRAVE, 600 High-resolution RGB images, 600 RGB-D images, and 600 point cloud images for each object. The Google scanner data provides 3 meshes with different resolutions (16k, 64k, and 512k polygons), textured versions of each mesh, Kinbody files for using the meshes with OpenRAVE.</p>

      <h4>Update Frequency</h4>
      <p>Yearly</p>

      <h4>License</h4>
      <p>Creative Commons Attribution 4.0 International (CC BY 4.0)</p>

      <h4>Documentation</h4>
      <p><a href="http://www.ycbbenchmarks.com/">http://www.ycbbenchmarks.com/</a></p>


      <h4>Contact</h4>
      <p><a href="mailto:bcalli@wpi.edu">bcalli@wpi.edu</a></p>

      <h4 name="usageexamples">Usage Examples</h4>
        <h5 class="dataatwork-category">Publications</h5>
        <ul class="dataatwork-list">
          <li>
            <a href="https://ieeexplore.ieee.org/abstract/document/7989594" class="" target="_none">Pre-touch sensing for sequential manipulation</a> by <a href="https://sensor.cs.washington.edu/jrs.html" target="_none">Boling Yang, Patrick Lancaster, Joshua R. Smith</a></a>
            <br>
            
          </li>          <li>
            <a href="https://ieeexplore.ieee.org/abstract/document/8304743" class="" target="_none">The Closure Signature: A Functional Approach to Model Underactuated Compliant Robotic Hands</a> by <a href="http://www.dii.unisi.it/~domenico/" target="_none">Maria Pozzi, Gionata Salvietti, Jo√£o Bimbo, Monica Malvezzi, Domenico Prattichizzo</a></a>
            <br>
            
          </li>          <li>
            <a href="https://ieeexplore.ieee.org/abstract/document/8460950" class="" target="_none">Label Fusion: A Pipeline for Generating Ground Truth Labels for Real RGBD Data of Cluttered Scenes</a> by <a href="https://groups.csail.mit.edu/locomotion/russt.html" target="_none">Pat Marion, Peter R. Florence, Lucas Manuelli, Russ Tedrake</a></a>
            <br>
            
          </li>          <li>
            <a href="https://ieeexplore.ieee.org/document/7254318" class="" target="_none">Benchmarking in Manipulation Research: Using the Yale-CMU-Berkeley Object and Model Set</a> by <a href="https://www.wpi.edu/people/faculty/bcalli" target="_none">Berk Calli, Aaron Walsman, Arjun Singh, Siddhartha Srinivasa, Pieter Abbeel, Aaron M Dollar</a></a>
            <br>
            
          </li>        </ul>

    </div>
    <div class="col-md-5 col-md-offset-1">
      <h3>Resources on AWS</h3>
      <ul class="resource-list">
        <li>
          <dl class="resource-list">
            <dt class="resource-description">Description</dt>
            <dd class="resource-description">Project data files</dd>
            <dt class="resource-type">Resource type</dt>
            <dd class="resource-type s3-bucket">S3 Bucket</dd>
            <dt class="resource-arn">Amazon Resource Name (ARN)</dt>
            <dd><code>arn:aws:s3:::ycb-benchmarks</code></dd>
            <dt class="resource-region">AWS Region</dt>
            <dd><code>us-east-1</code></dd>
            <dt class="resource-region"><a href="https://aws.amazon.com/cli/">AWS CLI</a> Access (No AWS account required)</dt>
            <dd><code>aws s3 ls s3://ycb-benchmarks/ --no-sign-request</code></dd>
            <dt class="resource-explore">Explore</dt>
            <dd><a href="https://ycb-benchmarks.s3.amazonaws.com/index.html">Browse Bucket</a></dd>
          </dl>
        </li>
      </ul>
    </div>
  </div>

    <hr/>
    <p><a href="https://github.com/awslabs/open-data-registry/blob/main/datasets/ycb-benchmarks.yaml">Edit this dataset entry on GitHub</a></p>
    <p><a href="/"><b>Home</b></a></p>
  </div>
  <script src="/js/tags.js"></script>
